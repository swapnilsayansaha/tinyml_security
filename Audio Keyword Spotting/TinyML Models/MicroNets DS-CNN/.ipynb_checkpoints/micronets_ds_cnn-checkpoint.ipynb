{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:21:00.0, compute capability: 8.6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gtda.time_series import SlidingWindow\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.backend import set_session\n",
    "config = tf.compat.v1.ConfigProto() \n",
    "config.gpu_options.allow_growth = True  \n",
    "config.log_device_placement = True  \n",
    "sess2 = tf.compat.v1.Session(config=config)\n",
    "set_session(sess2) \n",
    "from tensorflow.keras.utils import get_custom_objects\n",
    "from tensorflow.keras.layers import Activation \n",
    "from tensorflow.keras.backend import sigmoid\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, BatchNormalization, Flatten, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "import get_dataset as kws_data\n",
    "import kws_util\n",
    "import argparse\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will download data to /home/nesl/209as_sec/audio_ks/data\n",
      "Done getting data\n"
     ]
    }
   ],
   "source": [
    "Flags, unparsed = kws_util.parse_command()\n",
    "Flags.batch_size = 1\n",
    "Flags.window_size_ms = 40.0\n",
    "Flags.data_dir = '/home/nesl/209as_sec/audio_ks/data'\n",
    "print('We will download data to {:}'.format(Flags.data_dir))\n",
    "ds_train, ds_test, ds_val = kws_data.get_training_data(Flags)\n",
    "print(\"Done getting data\")\n",
    "train_shuffle_buffer_size = 85511\n",
    "val_shuffle_buffer_size = 10102\n",
    "test_shuffle_buffer_size = 4890\n",
    "\n",
    "ds_train = ds_train.shuffle(train_shuffle_buffer_size)\n",
    "ds_val = ds_val.shuffle(val_shuffle_buffer_size)\n",
    "ds_test = ds_test.shuffle(test_shuffle_buffer_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model and Perform Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 4890/4890 [01:13<00:00, 66.26it/s]\n"
     ]
    }
   ],
   "source": [
    "output_data = []\n",
    "labels = []\n",
    "interpreter = tf.lite.Interpreter('kws_micronet_s.tflite')\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "input_shape = input_details[0]['shape']\n",
    "input_scale, input_zero_point = input_details[0][\"quantization\"]\n",
    "\n",
    "for dat, label in tqdm(ds_test):\n",
    "    if input_details[0]['dtype'] == np.float32:\n",
    "        interpreter.set_tensor(input_details[0]['index'], dat)\n",
    "    elif input_details[0]['dtype'] == np.int8:\n",
    "        dat_q = np.array(dat/input_scale + input_zero_point, dtype=np.int8) \n",
    "        interpreter.set_tensor(input_details[0]['index'], dat_q)\n",
    "    else:\n",
    "        raise ValueError(\"TFLite file has input dtype {:}.  Only np.int8 and np.float32 are supported\".format(\n",
    "            input_details[0]['dtype']))\n",
    "    interpreter.invoke()\n",
    "    output_data.append(np.argmax(interpreter.get_tensor(output_details[0]['index'])))\n",
    "    labels.append(label[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8439672801635992\n"
     ]
    }
   ],
   "source": [
    "num_correct = np.sum(np.array(labels) == output_data)\n",
    "acc = num_correct / len(labels)\n",
    "print('Accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 4890/4890 [08:44<00:00,  9.32it/s]\n"
     ]
    }
   ],
   "source": [
    "output_data = []\n",
    "labels = []\n",
    "interpreter = tf.lite.Interpreter('kws_micronet_l.tflite')\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "input_shape = input_details[0]['shape']\n",
    "input_scale, input_zero_point = input_details[0][\"quantization\"]\n",
    "\n",
    "for dat, label in tqdm(ds_test):\n",
    "    if input_details[0]['dtype'] == np.float32:\n",
    "        interpreter.set_tensor(input_details[0]['index'], dat)\n",
    "    elif input_details[0]['dtype'] == np.int8:\n",
    "        dat_q = np.array(dat/input_scale + input_zero_point, dtype=np.int8) \n",
    "        interpreter.set_tensor(input_details[0]['index'], dat_q)\n",
    "    else:\n",
    "        raise ValueError(\"TFLite file has input dtype {:}.  Only np.int8 and np.float32 are supported\".format(\n",
    "            input_details[0]['dtype']))\n",
    "    interpreter.invoke()\n",
    "    output_data.append(np.argmax(interpreter.get_tensor(output_details[0]['index'])))\n",
    "    labels.append(label[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8877300613496932\n"
     ]
    }
   ],
   "source": [
    "num_correct = np.sum(np.array(labels) == output_data)\n",
    "acc = num_correct / len(labels)\n",
    "print('Accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
