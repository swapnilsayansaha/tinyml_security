{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PGD_cifar10.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.19.5\n",
        "!pip install pandas==1.3.1  \n",
        "!pip install tensorflow-gpu==2.5.0\n",
        "!pip install tensorflow-datasets==4.4.0\n",
        "!pip install tensorflow-hub==0.12.0  \n",
        "!pip install giotto-tda==0.5.1\n",
        "!pip install keras==2.7.0 \n",
        "!pip install keras-flops==0.1.2\n",
        "!pip install keras-tcn==3.3.0\n",
        "!pip install matplotlib==3.5.0\n",
        "!pip install jupyterlab==3.0.16\n",
        "!pip install torch==1.10.0             \n",
        "!pip install torchvision==0.11.1\n",
        "!pip install tqdm==4.61.2\n",
        "!pip install pytorch2keras==0.2.4 \n",
        "!pip install onnx==1.8.0              \n",
        "!pip install onnx-tf==1.8.0\n",
        "!pip install onnx2keras==0.0.24\n",
        "!pip install librosa==0.8.1\n",
        "!pip install kapre==0.2.0\n",
        "!pip install scikit-learn==0.24.2             \n",
        "!pip install scipy==1.7.0 "
      ],
      "metadata": {
        "id": "VaQbvJAZgvap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from gtda.time_series import SlidingWindow\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.keras.backend import set_session\n",
        "config = tf.compat.v1.ConfigProto() \n",
        "config.gpu_options.allow_growth = True  \n",
        "config.log_device_placement = True  \n",
        "sess2 = tf.compat.v1.Session(config=config)\n",
        "set_session(sess2) \n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.applications import imagenet_utils\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img"
      ],
      "metadata": {
        "id": "X3vaiBtRgytY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, decode_predictions, preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "import matplotlib.pyplot as plt\n",
        "inputShape = (224, 224)\n",
        "preprocess = imagenet_utils.preprocess_input"
      ],
      "metadata": {
        "id": "qMHCLHDjg2VD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import cv2"
      ],
      "metadata": {
        "id": "W-WhVgOQg4Cy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_name = \"cifar10\"\n",
        "(ds_train, ds_test), ds_info = tfds.load(\n",
        "    dataset_name, split=[\"train\", \"test\"], with_info=True, as_supervised=True\n",
        ")\n",
        "NUM_CLASSES = ds_info.features[\"label\"].num_classes\n",
        "\n",
        "IMG_SIZE = 224\n",
        "batch_size = 1\n",
        "size = (IMG_SIZE, IMG_SIZE)\n",
        "ds_train = ds_train.map(lambda image, label: (tf.image.resize(image, size), label))\n",
        "ds_test = ds_test.map(lambda image, label: (tf.image.resize(image, size), label))\n",
        "\n",
        "def input_preprocess(image, label):\n",
        "    label = tf.one_hot(label, NUM_CLASSES)\n",
        "    return image, label\n",
        "\n",
        "\n",
        "ds_train = ds_train.map(\n",
        "    input_preprocess, num_parallel_calls=tf.data.AUTOTUNE\n",
        ")\n",
        "ds_train = ds_train.batch(batch_size=batch_size, drop_remainder=True)\n",
        "ds_train = ds_train.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "ds_test = ds_test.map(input_preprocess)\n",
        "ds_test = ds_test.batch(batch_size=batch_size, drop_remainder=True)"
      ],
      "metadata": {
        "id": "IrUDDbXKg9Mx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"\" #@param {type:\"string\"}\n",
        "model  = tf.keras.models.load_model(model_path)\n"
      ],
      "metadata": {
        "id": "RvPNBSllg8Oi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JzWsvnSueeAV"
      },
      "outputs": [],
      "source": [
        "iterations = 7\n",
        "alpha = 2\n",
        "epsilon = 8/255  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pgd_generation\n",
        "image_count = 0\n",
        "flag = 0\n",
        "orig_label = []\n",
        "for x_train, labels in ds_train:\n",
        "  gen_img = tf.identity(x_train)\n",
        "  gen_img = gen_img + tf.random.uniform(gen_img.get_shape().as_list(), minval=-epsilon, maxval=epsilon, dtype=tf.dtypes.float32)\n",
        "  x_temp = x_train.numpy()\n",
        "  for iters in range(iterations):\n",
        "    imgv = tf.Variable(gen_img)\n",
        "    with tf.GradientTape() as tape:\n",
        "      tape.watch(imgv)\n",
        "      predictions = model(imgv)\n",
        "      loss = tf.keras.losses.CategoricalCrossentropy()(labels, predictions)\n",
        "      grads = tape.gradient(loss,imgv)\n",
        "    signed_grads = tf.sign(grads)\n",
        "    gen_img = gen_img + (alpha*signed_grads)\n",
        "    gen_img = tf.clip_by_value(gen_img, x_train-epsilon, x_train+epsilon)\n",
        "  for i in range(16):\n",
        "    image_count += 1\n",
        "    if image_count>200:\n",
        "      flag = 1\n",
        "      break\n",
        "    orig_label.append(labels[i])\n",
        "    gen_image = gen_img.numpy()[i]*255\n",
        "    orig_image = x_train.numpy()[i]*255\n",
        "    path_to_generated_and_original_image= \"\" #@param {type:\"string\"}\n",
        "    imwrite(path_to_generated_and_original_image +str(image_count)+'_gen_img.png',np.clip(gen_image, 0, 255).astype('uint8'))\n",
        "    imwrite(path_to_generated_and_original_image+str(image_count)+'_orig_img.png',np.clip(orig_image, 0, 255).astype('uint8'))\n",
        "  if flag==1:\n",
        "    break "
      ],
      "metadata": {
        "id": "S29OBJunegKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generated_images = []\n",
        "for i in range(1, 201):\n",
        "  x = cv2.imread(path_to_generated_and_original_image+str(i)+'_gen_img.png')\n",
        "  generated_images.append(x)\n",
        "generated_images = tf.convert_to_tensor(generated_images)\n",
        "orig_label = tf.convert_to_tensor(orig_label)"
      ],
      "metadata": {
        "id": "zZiL8Lp6eiQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_images = []\n",
        "for i in range(1, 201):\n",
        "  x = cv2.imread(path_to_generated_and_original_image+str(i)+'_orig_img.png')\n",
        "  original_images.append(x)\n",
        "original_images = tf.convert_to_tensor(generated_images)"
      ],
      "metadata": {
        "id": "KYntQhHpgECA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(generated_images,orig_label, verbose = 1) # adversarial accuracy i.e. model accuracy on the perturbed data "
      ],
      "metadata": {
        "id": "pHl7K_NdgGn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "WQeoMba-gVy3"
      }
    }
  ]
}