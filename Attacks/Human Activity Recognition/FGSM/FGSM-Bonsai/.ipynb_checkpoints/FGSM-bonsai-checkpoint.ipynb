{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gtda.time_series import SlidingWindow\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.keras.backend import set_session\n",
    "import tensorflow as tf\n",
    "config = tf.compat.v1.ConfigProto() \n",
    "config.gpu_options.allow_growth = True  \n",
    "config.log_device_placement = True  \n",
    "sess2 = tf.compat.v1.Session(config=config)\n",
    "set_session(sess2)  \n",
    "import csv\n",
    "import random\n",
    "import itertools\n",
    "import glob\n",
    "import time\n",
    "import pickle\n",
    "from data_utils import *\n",
    "\n",
    "from tensorflow import keras\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.losses import MSE\n",
    "from edgeml_tf.tflite.bonsaiLayer import BonsaiLayer #modified bonsailayer to return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = '/home/nesl/209as_sec/human_act/Data/Activity_Dataset/'\n",
    "model_dir = 'trained_models/'\n",
    "window_size = 550\n",
    "stride = 50\n",
    "channels = 2\n",
    "\n",
    "X_tr, Y_tr, X_test, Y_test = import_auritus_activity_dataset(dataset_folder = f, \n",
    "                                use_timestamp=False, \n",
    "                                shuffle=True, \n",
    "                                window_size = window_size, stride = stride, \n",
    "                                return_test_set = True, test_set_size = 300,channels=2)\n",
    "print(X_tr.shape)\n",
    "print(Y_tr.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feat_size = 10\n",
    "featX_tr = np.zeros((X_tr.shape[0],feat_size))\n",
    "featX_test = np.zeros((X_test.shape[0],feat_size))\n",
    "for i in range(X_tr.shape[0]):\n",
    "    cur_win = X_tr[i]\n",
    "    featX_tr[i,0] = np.min(cur_win[:,0])\n",
    "    featX_tr[i,1] = np.min(cur_win[:,1])\n",
    "    featX_tr[i,2] = np.max(cur_win[:,0])\n",
    "    featX_tr[i,3] = np.max(cur_win[:,1])\n",
    "    featX_tr[i,4] = featX_tr[i,2]-featX_tr[i,0]\n",
    "    featX_tr[i,5] = featX_tr[i,3]-featX_tr[i,1]\n",
    "    featX_tr[i,6] = np.var(cur_win[:,0])\n",
    "    featX_tr[i,7] = np.var(cur_win[:,1])\n",
    "    featX_tr[i,8] = np.sqrt(featX_tr[i,6])\n",
    "    featX_tr[i,9] = np.sqrt(featX_tr[i,7])  \n",
    "    \n",
    "for i in range(X_test.shape[0]):\n",
    "    cur_win = X_test[i]\n",
    "    featX_test[i,0] = np.min(cur_win[:,0])\n",
    "    featX_test[i,1] = np.min(cur_win[:,1])\n",
    "    featX_test[i,2] = np.max(cur_win[:,0])\n",
    "    featX_test[i,3] = np.max(cur_win[:,1])\n",
    "    featX_test[i,4] = featX_test[i,2]-featX_test[i,0]\n",
    "    featX_test[i,5] = featX_test[i,3]-featX_test[i,1]\n",
    "    featX_test[i,6] = np.var(cur_win[:,0])\n",
    "    featX_test[i,7] = np.var(cur_win[:,1])\n",
    "    featX_test[i,8] = np.sqrt(featX_test[i,6])\n",
    "    featX_test[i,9] = np.sqrt(featX_test[i,7])\n",
    "\n",
    "dataDimension = featX_tr.shape[1]\n",
    "numClasses = Y_tr.shape[1]\n",
    "Xtrain = featX_tr\n",
    "Ytrain = Y_tr\n",
    "Xtest = featX_test\n",
    "Ytest = Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = np.load( glob.glob(model_dir + \"/**/Z.npy\", recursive = True)[0], allow_pickle=True )\n",
    "W = np.load( glob.glob(model_dir + \"/**/W.npy\", recursive = True)[0], allow_pickle=True )\n",
    "V = np.load( glob.glob(model_dir + \"/**/V.npy\", recursive = True)[0], allow_pickle=True )\n",
    "T = np.load( glob.glob(model_dir + \"/**/T.npy\", recursive = True)[0], allow_pickle=True )\n",
    "hyperparams = np.load(glob.glob(model_dir + \"/**/hyperParam.npy\", \n",
    "                            recursive = True)[0], allow_pickle=True ).item()\n",
    "\n",
    "n_dim = hyperparams['dataDim']\n",
    "projectionDimension = hyperparams['projDim']\n",
    "numClasses = hyperparams['numClasses']\n",
    "depth = hyperparams['depth']\n",
    "sigma = hyperparams['sigma']\n",
    "\n",
    "dense = BonsaiLayer( numClasses, n_dim, projectionDimension, depth, sigma )\n",
    "model = keras.Sequential([\n",
    "keras.layers.InputLayer(n_dim),\n",
    "dense\n",
    "])\n",
    "\n",
    "dummy_tensor = tf.convert_to_tensor( np.zeros((1,n_dim), np.float32) )\n",
    "out_tensor = model(dummy_tensor)\n",
    "model.summary()\n",
    "dense.set_weights( [Z, W, V, T] )\n",
    "model.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgsm_attack(model, image, label, eps):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(image)\n",
    "        pred = model(image)\n",
    "        loss = MSE(label, pred)\n",
    "        gradient = tape.gradient(loss, image)\n",
    "        signedGrad = tf.sign(gradient)\n",
    "        adversary = (image + (signedGrad * eps)).numpy()\n",
    "        return adversary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = [0.05,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0,1.5,2.0,5.0,10.0,15.0,20.0,30.0,40.0,50.0]\n",
    "accu_num = []\n",
    "for item in eps:\n",
    "    countadv = 0\n",
    "    for i in tqdm(range(len(Xtest))):\n",
    "        audio = Xtest[i,:].reshape(1,len(Xtest[i,:]))\n",
    "        label = Y_test[i,:]\n",
    "        audioPred = model.predict(audio)\n",
    "        audioPred = audioPred.argmax()\n",
    "        adversary = fgsm_attack(model,audio, label, eps=item)\n",
    "        pred = model.predict(adversary)\n",
    "        adversaryPred = pred.argmax()\n",
    "        if audioPred == adversaryPred:\n",
    "            countadv += 1\n",
    "\n",
    "    print(\"Adversarial accuracy : \", countadv / len(Xtest))\n",
    "    accu_num.append(countadv / len(Xtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accu_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
