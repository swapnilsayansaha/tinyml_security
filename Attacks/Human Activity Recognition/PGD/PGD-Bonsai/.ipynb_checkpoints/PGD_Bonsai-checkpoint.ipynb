{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gtda.time_series import SlidingWindow\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.keras.backend import set_session\n",
    "import tensorflow as tf\n",
    "config = tf.compat.v1.ConfigProto() \n",
    "config.gpu_options.allow_growth = True  \n",
    "config.log_device_placement = True  \n",
    "sess2 = tf.compat.v1.Session(config=config)\n",
    "set_session(sess2)  \n",
    "import csv\n",
    "import random\n",
    "import itertools\n",
    "import glob\n",
    "import time\n",
    "import pickle\n",
    "from data_utils import *\n",
    "\n",
    "from tensorflow import keras\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.losses import MSE\n",
    "from edgeml_tf.tflite.bonsaiLayer import BonsaiLayer #modified bonsailayer to return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = '/home/nesl/209as_sec/human_act/Data/Activity_Dataset/'\n",
    "model_dir = 'trained_models/'\n",
    "window_size = 550\n",
    "stride = 50\n",
    "channels = 2\n",
    "\n",
    "X_tr, Y_tr, X_test, Y_test = import_auritus_activity_dataset(dataset_folder = f, \n",
    "                                use_timestamp=False, \n",
    "                                shuffle=True, \n",
    "                                window_size = window_size, stride = stride, \n",
    "                                return_test_set = True, test_set_size = 300,channels=2)\n",
    "print(X_tr.shape)\n",
    "print(Y_tr.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feat_size = 10\n",
    "featX_tr = np.zeros((X_tr.shape[0],feat_size))\n",
    "featX_test = np.zeros((X_test.shape[0],feat_size))\n",
    "for i in range(X_tr.shape[0]):\n",
    "    cur_win = X_tr[i]\n",
    "    featX_tr[i,0] = np.min(cur_win[:,0])\n",
    "    featX_tr[i,1] = np.min(cur_win[:,1])\n",
    "    featX_tr[i,2] = np.max(cur_win[:,0])\n",
    "    featX_tr[i,3] = np.max(cur_win[:,1])\n",
    "    featX_tr[i,4] = featX_tr[i,2]-featX_tr[i,0]\n",
    "    featX_tr[i,5] = featX_tr[i,3]-featX_tr[i,1]\n",
    "    featX_tr[i,6] = np.var(cur_win[:,0])\n",
    "    featX_tr[i,7] = np.var(cur_win[:,1])\n",
    "    featX_tr[i,8] = np.sqrt(featX_tr[i,6])\n",
    "    featX_tr[i,9] = np.sqrt(featX_tr[i,7])  \n",
    "    \n",
    "for i in range(X_test.shape[0]):\n",
    "    cur_win = X_test[i]\n",
    "    featX_test[i,0] = np.min(cur_win[:,0])\n",
    "    featX_test[i,1] = np.min(cur_win[:,1])\n",
    "    featX_test[i,2] = np.max(cur_win[:,0])\n",
    "    featX_test[i,3] = np.max(cur_win[:,1])\n",
    "    featX_test[i,4] = featX_test[i,2]-featX_test[i,0]\n",
    "    featX_test[i,5] = featX_test[i,3]-featX_test[i,1]\n",
    "    featX_test[i,6] = np.var(cur_win[:,0])\n",
    "    featX_test[i,7] = np.var(cur_win[:,1])\n",
    "    featX_test[i,8] = np.sqrt(featX_test[i,6])\n",
    "    featX_test[i,9] = np.sqrt(featX_test[i,7])\n",
    "\n",
    "dataDimension = featX_tr.shape[1]\n",
    "numClasses = Y_tr.shape[1]\n",
    "Xtrain = featX_tr\n",
    "Ytrain = Y_tr\n",
    "Xtest = featX_test\n",
    "Ytest = Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = np.load( glob.glob(model_dir + \"/**/Z.npy\", recursive = True)[0], allow_pickle=True )\n",
    "W = np.load( glob.glob(model_dir + \"/**/W.npy\", recursive = True)[0], allow_pickle=True )\n",
    "V = np.load( glob.glob(model_dir + \"/**/V.npy\", recursive = True)[0], allow_pickle=True )\n",
    "T = np.load( glob.glob(model_dir + \"/**/T.npy\", recursive = True)[0], allow_pickle=True )\n",
    "hyperparams = np.load(glob.glob(model_dir + \"/**/hyperParam.npy\", \n",
    "                            recursive = True)[0], allow_pickle=True ).item()\n",
    "\n",
    "n_dim = hyperparams['dataDim']\n",
    "projectionDimension = hyperparams['projDim']\n",
    "numClasses = hyperparams['numClasses']\n",
    "depth = hyperparams['depth']\n",
    "sigma = hyperparams['sigma']\n",
    "\n",
    "dense = BonsaiLayer( numClasses, n_dim, projectionDimension, depth, sigma )\n",
    "model = keras.Sequential([\n",
    "keras.layers.InputLayer(n_dim),\n",
    "dense\n",
    "])\n",
    "\n",
    "dummy_tensor = tf.convert_to_tensor( np.zeros((1,n_dim), np.float32) )\n",
    "out_tensor = model(dummy_tensor)\n",
    "model.summary()\n",
    "dense.set_weights( [Z, W, V, T] )\n",
    "model.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pgd_attack(model,iterations, image, label, alpha, eps):\n",
    "    gen_img = tf.identity(image)\n",
    "    gen_img = tf.cast(gen_img,dtype=tf.dtypes.float32)\n",
    "    gen_img = gen_img + tf.random.uniform(gen_img.get_shape().as_list(), minval=-eps, \n",
    "                                          maxval=eps, dtype=tf.dtypes.float32)\n",
    "    x_temp = image\n",
    "    for iter in range(iterations):\n",
    "        imgv = tf.Variable(gen_img)\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(imgv)\n",
    "            predictions = model(imgv)\n",
    "            loss = tf.keras.losses.CategoricalCrossentropy()(label, predictions)\n",
    "            grads = tape.gradient(loss,imgv)\n",
    "        signed_grads = tf.sign(grads)\n",
    "        gen_img = gen_img + (alpha*signed_grads)\n",
    "        gen_img = tf.clip_by_value(gen_img, image-eps, image+eps)\n",
    "    return gen_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = [0.1,0.3,0.5,0.7,0.9,1.0,2.0]\n",
    "iterations = 5\n",
    "alpha = [0.1,0.3,0.5,0.7,0.9,1.0]\n",
    "take_size = 4890\n",
    "accu_num = []\n",
    "eps_list = []\n",
    "alpha_list = []\n",
    "\n",
    "for al in alpha:\n",
    "    for item in eps:\n",
    "        countadv = 0\n",
    "        for i in tqdm(range(len(Xtest))):\n",
    "            audio = Xtest[i,:].reshape(1,len(Xtest[i,:]))\n",
    "            label = Y_test[i,:].reshape(9,1)\n",
    "            audioPred = model.predict(audio)\n",
    "            audioPred = audioPred.argmax()\n",
    "            adversary = pgd_attack(model,iterations,audio, label, alpha=al, eps=item)\n",
    "            pred = model.predict(adversary)\n",
    "            adversaryPred = pred.argmax()\n",
    "            if audioPred == adversaryPred:\n",
    "                countadv += 1\n",
    "\n",
    "        print(\"Adversarial accuracy : \", countadv / len(Xtest))\n",
    "        accu_num.append(countadv / len(Xtest))\n",
    "        eps_list.append(item)\n",
    "        alpha_list.append(al)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accu_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
