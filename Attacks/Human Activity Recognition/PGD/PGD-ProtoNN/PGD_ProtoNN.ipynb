{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b173d15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gtda.time_series import SlidingWindow\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.keras.backend import set_session\n",
    "import tensorflow as tf\n",
    "config = tf.compat.v1.ConfigProto() \n",
    "config.gpu_options.allow_growth = True  \n",
    "config.log_device_placement = True  \n",
    "sess2 = tf.compat.v1.Session(config=config)\n",
    "set_session(sess2)  \n",
    "import csv\n",
    "import random\n",
    "import itertools\n",
    "import glob\n",
    "import time\n",
    "import pickle\n",
    "from data_utils import *\n",
    "\n",
    "from tensorflow import keras\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.losses import MSE\n",
    "from edgeml_tf.tflite.protoNNLayer import ProtoNNLayer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1142c384",
   "metadata": {},
   "source": [
    "## Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55e259b",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = '/home/nesl/209as_sec/human_act/Data/Activity_Dataset/'\n",
    "model_dir = 'trained_models/'\n",
    "window_size = 550\n",
    "stride = 50\n",
    "channels = 2\n",
    "\n",
    "X_tr, Y_tr, X_test, Y_test = import_auritus_activity_dataset(dataset_folder = f, \n",
    "                                use_timestamp=False, \n",
    "                                shuffle=True, \n",
    "                                window_size = window_size, stride = stride, \n",
    "                                return_test_set = True, test_set_size = 300,channels=2)\n",
    "print(X_tr.shape)\n",
    "print(Y_tr.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8bfadd",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a1419c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_size = 10\n",
    "featX_tr = np.zeros((X_tr.shape[0],feat_size))\n",
    "featX_test = np.zeros((X_test.shape[0],feat_size))\n",
    "for i in range(X_tr.shape[0]):\n",
    "    cur_win = X_tr[i]\n",
    "    featX_tr[i,0] = np.min(cur_win[:,0])\n",
    "    featX_tr[i,1] = np.min(cur_win[:,1])\n",
    "    featX_tr[i,2] = np.max(cur_win[:,0])\n",
    "    featX_tr[i,3] = np.max(cur_win[:,1])\n",
    "    featX_tr[i,4] = featX_tr[i,2]-featX_tr[i,0]\n",
    "    featX_tr[i,5] = featX_tr[i,3]-featX_tr[i,1]\n",
    "    featX_tr[i,6] = np.var(cur_win[:,0])\n",
    "    featX_tr[i,7] = np.var(cur_win[:,1])\n",
    "    featX_tr[i,8] = np.sqrt(featX_tr[i,6])\n",
    "    featX_tr[i,9] = np.sqrt(featX_tr[i,7])  \n",
    "    \n",
    "for i in range(X_test.shape[0]):\n",
    "    cur_win = X_test[i]\n",
    "    featX_test[i,0] = np.min(cur_win[:,0])\n",
    "    featX_test[i,1] = np.min(cur_win[:,1])\n",
    "    featX_test[i,2] = np.max(cur_win[:,0])\n",
    "    featX_test[i,3] = np.max(cur_win[:,1])\n",
    "    featX_test[i,4] = featX_test[i,2]-featX_test[i,0]\n",
    "    featX_test[i,5] = featX_test[i,3]-featX_test[i,1]\n",
    "    featX_test[i,6] = np.var(cur_win[:,0])\n",
    "    featX_test[i,7] = np.var(cur_win[:,1])\n",
    "    featX_test[i,8] = np.sqrt(featX_test[i,6])\n",
    "    featX_test[i,9] = np.sqrt(featX_test[i,7])\n",
    "    \n",
    "x_train = featX_tr\n",
    "y_train = Y_tr\n",
    "x_test = featX_test\n",
    "y_test = Y_test\n",
    "numClasses = Y_tr.shape[1]\n",
    "dataDimension = x_train.shape[1]\n",
    "\n",
    "mean = np.mean(x_train, 0)\n",
    "std = np.std(x_train, 0)\n",
    "std[std[:] < 0.000001] = 1\n",
    "x_train = (x_train - mean) / std\n",
    "x_test = (x_test - mean) / std\n",
    "Y_tr_int = np.argmax(Y_tr, axis=1)\n",
    "Y_test_int = np.argmax(Y_test,axis=1)\n",
    "\n",
    "shutil.rmtree('earable_dataset/', ignore_errors=True)\n",
    "os.mkdir('earable_dataset/')\n",
    "train = np.concatenate([Y_tr_int.reshape((Y_tr_int.shape[0],1)),x_train],axis=1)\n",
    "with open('earable_dataset/train.npy','wb') as f:\n",
    "    np.save(f,train)\n",
    "test = np.concatenate([Y_test_int.reshape((Y_test_int.shape[0],1)),x_test],axis=1)\n",
    "with open('earable_dataset/test.npy','wb') as f:\n",
    "    np.save(f,test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44681cff",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cfdd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = np.load( glob.glob(model_dir + \"/**/Z.npy\", recursive = True)[0], allow_pickle=True )\n",
    "W = np.load( glob.glob(model_dir + \"/**/W.npy\", recursive = True)[0], allow_pickle=True )\n",
    "B = np.load( glob.glob(model_dir + \"/**/B.npy\", recursive = True)[0], allow_pickle=True )\n",
    "gamma = np.load( glob.glob(model_dir + \"/**/gamma.npy\", recursive = True)[0], allow_pickle=True )\n",
    "\n",
    "\n",
    "n_dim = inputDimension = W.shape[0]\n",
    "projectionDimension = W.shape[1]\n",
    "numPrototypes = B.shape[1]\n",
    "numOutputLabels = Z.shape[0]\n",
    "\n",
    "dense = ProtoNNLayer( inputDimension, projectionDimension, numPrototypes, numOutputLabels, gamma )\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.InputLayer(n_dim),\n",
    "    dense\n",
    "])\n",
    "\n",
    "dummy_tensor = tf.convert_to_tensor( np.zeros((1,n_dim), np.float32) )\n",
    "out_tensor = model( dummy_tensor )\n",
    "\n",
    "model.summary()\n",
    "\n",
    "dense.set_weights( [W, B, Z] )\n",
    "model.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7605381e",
   "metadata": {},
   "source": [
    "# Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bce917",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pgd_attack(model,iterations, image, label, alpha, eps):\n",
    "    gen_img = tf.identity(image)\n",
    "    gen_img = tf.cast(gen_img,dtype=tf.dtypes.float32)\n",
    "    gen_img = gen_img + tf.random.uniform(gen_img.get_shape().as_list(), minval=-eps, \n",
    "                                          maxval=eps, dtype=tf.dtypes.float32)\n",
    "    x_temp = image\n",
    "    for iter in range(iterations):\n",
    "        imgv = tf.Variable(gen_img)\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(imgv)\n",
    "            predictions = model(imgv)\n",
    "            loss = tf.keras.losses.CategoricalCrossentropy()(label, predictions)\n",
    "            grads = tape.gradient(loss,imgv)\n",
    "        signed_grads = tf.sign(grads)\n",
    "        gen_img = gen_img + (alpha*signed_grads)\n",
    "        gen_img = tf.clip_by_value(gen_img, image-eps, image+eps)\n",
    "    return gen_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a33f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = [0.1,0.3,0.5,0.7,0.9,1.0,2.0]\n",
    "iterations = 5\n",
    "alpha = [0.1,0.3,0.5,0.7,0.9,1.0]\n",
    "take_size = 4890\n",
    "accu_num = []\n",
    "eps_list = []\n",
    "alpha_list = []\n",
    "\n",
    "for al in alpha:\n",
    "    for item in eps:\n",
    "        countadv = 0\n",
    "        for i in tqdm(range(len(x_test))):\n",
    "            audio = x_test[i,:].reshape(1,len(x_test[i,:]))\n",
    "            label = y_test[i,:].reshape(1,9)\n",
    "            audioPred = model.predict(audio)\n",
    "            audioPred = audioPred.argmax()\n",
    "            adversary = pgd_attack(model,iterations,audio, label, alpha=al, eps=item)\n",
    "            pred = model.predict(adversary)\n",
    "            adversaryPred = pred.argmax()\n",
    "            if audioPred == adversaryPred:\n",
    "                countadv += 1\n",
    "\n",
    "        print(\"Adversarial accuracy : \", countadv / len(x_test))\n",
    "        accu_num.append(countadv / len(x_test))\n",
    "        eps_list.append(item)\n",
    "        alpha_list.append(al)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740df9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "accu_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dababbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635a138a",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bd34a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
