{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8f78d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gtda.time_series import SlidingWindow\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.backend import set_session\n",
    "config = tf.compat.v1.ConfigProto() \n",
    "config.gpu_options.allow_growth = True  \n",
    "config.log_device_placement = True  \n",
    "sess2 = tf.compat.v1.Session(config=config)\n",
    "set_session(sess2) \n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.losses import MSE\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02be41e",
   "metadata": {},
   "source": [
    "## Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e95bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"cifar10\"\n",
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    dataset_name, split=[\"train\", \"test\"], with_info=True, as_supervised=True\n",
    ")\n",
    "NUM_CLASSES = ds_info.features[\"label\"].num_classes\n",
    "\n",
    "IMG_SIZE = 300\n",
    "batch_size = 1\n",
    "size = (IMG_SIZE, IMG_SIZE)\n",
    "ds_train = ds_train.map(lambda image, label: (tf.image.resize(image, size), label))\n",
    "ds_test = ds_test.map(lambda image, label: (tf.image.resize(image, size), label))\n",
    "\n",
    "def input_preprocess(image, label):\n",
    "    label = tf.one_hot(label, NUM_CLASSES)\n",
    "    return image, label\n",
    "\n",
    "\n",
    "ds_train = ds_train.map(\n",
    "    input_preprocess, num_parallel_calls=tf.data.AUTOTUNE\n",
    ")\n",
    "ds_train = ds_train.batch(batch_size=batch_size, drop_remainder=True)\n",
    "ds_train = ds_train.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "ds_test = ds_test.map(input_preprocess)\n",
    "ds_test = ds_test.batch(batch_size=batch_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10738725",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdfd3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('/home/nesl/209as_sec/cifar10/Large Models/EfficientNetV2B3/enetv2b3')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a872aa2f",
   "metadata": {},
   "source": [
    "## Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2f6664",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pgd_attack(model,iterations, image, label, alpha, eps):\n",
    "    gen_img = tf.identity(image)\n",
    "    gen_img = gen_img + tf.random.uniform(gen_img.get_shape().as_list(), minval=-eps, \n",
    "                                          maxval=eps, dtype=tf.dtypes.float32)\n",
    "    x_temp = image\n",
    "    for iter in range(iterations):\n",
    "        imgv = tf.Variable(gen_img)\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(imgv)\n",
    "            predictions = model(imgv)\n",
    "            loss = tf.keras.losses.CategoricalCrossentropy()(label, predictions)\n",
    "            grads = tape.gradient(loss,imgv)\n",
    "        signed_grads = tf.sign(grads)\n",
    "        gen_img = gen_img + (alpha*signed_grads)\n",
    "        gen_img = tf.clip_by_value(gen_img, image-eps, image+eps)\n",
    "    return gen_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9ec158",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = [0.1,0.3,0.5,0.7,0.9,1.0,2.0]\n",
    "iterations = 5\n",
    "alpha = [0.1,0.3,0.5,0.7,0.9,1.0]\n",
    "take_size = 1000\n",
    "accu_num = []\n",
    "eps_list = []\n",
    "alpha_list = []\n",
    "\n",
    "for al in alpha:\n",
    "    for item in eps:\n",
    "        countadv = 0\n",
    "        for image, label in tqdm(ds_test.take(take_size)):\n",
    "            imageLabel = np.array(label).argmax()\n",
    "            imagePred = model.predict(image)\n",
    "            imagePred = imagePred.argmax()\n",
    "            adversary = pgd_attack(model,iterations,image, label, alpha=al, eps=item)\n",
    "            pred = model.predict(adversary)\n",
    "            adversaryPred = pred[0].argmax()\n",
    "            if imagePred == adversaryPred:\n",
    "                countadv += 1\n",
    "            \n",
    "        print(\"Adversarial accuracy : \", countadv / take_size)\n",
    "        accu_num.append(countadv / take_size)\n",
    "        eps_list.append(item)\n",
    "        alpha_list.append(al)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5215058",
   "metadata": {},
   "outputs": [],
   "source": [
    "accu_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021a8e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c5a098",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
