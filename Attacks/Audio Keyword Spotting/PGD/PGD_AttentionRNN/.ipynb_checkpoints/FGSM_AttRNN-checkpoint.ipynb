{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0e78df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gtda.time_series import SlidingWindow\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.backend import set_session\n",
    "config = tf.compat.v1.ConfigProto() \n",
    "config.gpu_options.allow_growth = True  \n",
    "config.log_device_placement = True  \n",
    "sess2 = tf.compat.v1.Session(config=config)\n",
    "set_session(sess2) \n",
    "from tensorflow.keras.utils import get_custom_objects\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.losses import MSE\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from kapre.time_frequency import Melspectrogram, Spectrogram\n",
    "import librosa\n",
    "import SpeechDownloader\n",
    "import SpeechGenerator\n",
    "import SpeechModels\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66046c0d",
   "metadata": {},
   "source": [
    "## Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfd9a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "gscInfo, nCategs = SpeechDownloader.PrepareGoogleSpeechCmd(version=2, task='35word')\n",
    "sr = 16000 \n",
    "iLen = 16000\n",
    "trainGen = SpeechGenerator.SpeechGen(gscInfo['train']['files'], gscInfo['train']['labels'], shuffle=True)\n",
    "valGen   = SpeechGenerator.SpeechGen(gscInfo['val']['files'], gscInfo['val']['labels'], shuffle=True)\n",
    "testGen  = SpeechGenerator.SpeechGen(gscInfo['test']['files'], gscInfo['test']['labels'], shuffle=False, batch_size=len(gscInfo['test']['files']))\n",
    "testRGen = SpeechGenerator.SpeechGen(gscInfo['testREAL']['files'], gscInfo['testREAL']['labels'], shuffle=False, batch_size=len(gscInfo['testREAL']['files']))\n",
    "audios, classes = valGen.__getitem__(5)\n",
    "x_test, y_test = testGen.__getitem__(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d0eccc",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e231cf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SpeechModels.AttRNNSpeechModel(nCategs, samplingrate = sr, inputLength = None)#, rnn_func=L.LSTM)\n",
    "model.load_weights('model-attRNN.h5')\n",
    "model.compile(optimizer='adam', loss=['sparse_categorical_crossentropy'], metrics=['sparse_categorical_accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6b0065",
   "metadata": {},
   "source": [
    "## Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe7646d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgsm_attack(model, image, label, eps):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(image)\n",
    "        pred = model(image)\n",
    "        loss = MSE(label, pred)\n",
    "        gradient = tape.gradient(loss, image)\n",
    "        signedGrad = tf.sign(gradient)\n",
    "        adversary = (image + (signedGrad * eps)).numpy()\n",
    "        return adversary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2530d112",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = [0.05,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0,1.5,2.0,5.0,10.0,15.0,20.0,30.0,40.0,50.0]\n",
    "accu_num = []\n",
    "for item in eps:\n",
    "    countadv = 0\n",
    "    for i in tqdm(range(len(x_test))):\n",
    "        audio = x_test[i,:].reshape(1,len(x_test[i,:]))\n",
    "        label = np.array(tf.one_hot(y_test[i], max(set(y_test))+1)).reshape(1,max(set(y_test))+1)\n",
    "        audioPred = model.predict(audio)\n",
    "        audioPred = audioPred.argmax()\n",
    "        adversary = fgsm_attack(model,audio, label, eps=item)\n",
    "        pred = model.predict(adversary)\n",
    "        adversaryPred = pred[0].argmax()\n",
    "        if audioPred == adversaryPred:\n",
    "            countadv += 1\n",
    "\n",
    "    print(\"Adversarial accuracy : \", countadv / len(x_test))\n",
    "    accu_num.append(countadv / len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67deec2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "accu_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc944d8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
