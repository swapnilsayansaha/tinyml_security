{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94abae1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gtda.time_series import SlidingWindow\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.backend import set_session\n",
    "config = tf.compat.v1.ConfigProto() \n",
    "config.gpu_options.allow_growth = True  \n",
    "config.log_device_placement = True  \n",
    "sess2 = tf.compat.v1.Session(config=config)\n",
    "set_session(sess2) \n",
    "from tensorflow.keras.utils import get_custom_objects\n",
    "from tensorflow.keras.backend import sigmoid\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.losses import MSE\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "import get_dataset as kws_data\n",
    "import kws_util\n",
    "import argparse\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edaff5b4",
   "metadata": {},
   "source": [
    "## Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2833e462",
   "metadata": {},
   "outputs": [],
   "source": [
    "Flags, unparsed = kws_util.parse_command()\n",
    "Flags.window_size_ms=40.0\n",
    "Flags.window_stride_ms=20.0\n",
    "Flags.batch_size = 1\n",
    "Flags.data_dir = '/home/nesl/209as_sec/audio_ks/data'\n",
    "print('We will download data to {:}'.format(Flags.data_dir))\n",
    "ds_train, ds_test, ds_val = kws_data.get_training_data(Flags)\n",
    "print(\"Done getting data\")\n",
    "train_shuffle_buffer_size = 85511\n",
    "val_shuffle_buffer_size = 10102\n",
    "test_shuffle_buffer_size = 4890\n",
    "\n",
    "ds_train = ds_train.shuffle(train_shuffle_buffer_size)\n",
    "ds_val = ds_val.shuffle(val_shuffle_buffer_size)\n",
    "ds_test = ds_test.shuffle(test_shuffle_buffer_size)\n",
    "\n",
    "ds_train = ds_train.map(lambda x, y: (x, tf.one_hot(y, depth=12)))\n",
    "ds_val = ds_val.map(lambda x, y: (x, tf.one_hot(y, depth=12)))\n",
    "ds_test = ds_test.map(lambda x, y: (x, tf.one_hot(y, depth=12)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ec7924",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be634ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('/home/nesl/209as_sec/audio_ks/Big Models/LSTM/lstm_large.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd33e79f",
   "metadata": {},
   "source": [
    "## Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b016a799",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgsm_attack(model, image, label, eps):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(image)\n",
    "        pred = model(image)\n",
    "        loss = MSE(label, pred)\n",
    "        gradient = tape.gradient(loss, image)\n",
    "        signedGrad = tf.sign(gradient)\n",
    "        adversary = (image + (signedGrad * eps)).numpy()\n",
    "        return adversary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5685715",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = [0.05,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0,1.5,2.0,5.0,10.0,15.0,20.0,30.0,40.0,50.0]\n",
    "accu_num = []\n",
    "for item in eps:\n",
    "    countadv = 0\n",
    "    for audio, label in tqdm(ds_test):\n",
    "        audioLabel = np.array(label).argmax()\n",
    "        audioPred = model.predict(audio)\n",
    "        audioPred = audioPred.argmax()\n",
    "        adversary = fgsm_attack(model,audio, label, eps=item)\n",
    "        pred = model.predict(adversary)\n",
    "        adversaryPred = pred[0].argmax()\n",
    "        if audioPred == adversaryPred:\n",
    "            countadv += 1\n",
    "\n",
    "    print(\"Adversarial accuracy : \", countadv / len(ds_test))\n",
    "    accu_num.append(countadv / len(ds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b47846",
   "metadata": {},
   "outputs": [],
   "source": [
    "accu_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a66deac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
